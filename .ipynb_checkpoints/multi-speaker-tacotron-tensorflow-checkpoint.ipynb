{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b330ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting appnope==0.1.0\n",
      "  Using cached appnope-0.1.0-py2.py3-none-any.whl (4.0 kB)\n",
      "Collecting audioread==2.1.5\n",
      "  Using cached audioread-2.1.5-py3-none-any.whl\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "  Using cached beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
      "Collecting bleach==1.5.0\n",
      "  Using cached bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting bs4==0.0.1\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: cachetools==2.0.1 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: certifi==2017.7.27.1 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 7)) (2017.7.27.1)\n",
      "Requirement already satisfied: chardet==3.0.4 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 8)) (3.0.4)\n",
      "Collecting click==6.7\n",
      "  Using cached click-6.7-py2.py3-none-any.whl (71 kB)\n",
      "Collecting cycler==0.10.0\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: decorator==4.1.2 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 11)) (4.1.2)\n",
      "Requirement already satisfied: dill==0.2.7.1 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 12)) (0.2.7.1)\n",
      "Collecting ffprobe==0.5\n",
      "  Using cached ffprobe-0.5-py3-none-any.whl\n",
      "Collecting Flask==0.12.2\n",
      "  Using cached Flask-0.12.2-py2.py3-none-any.whl (83 kB)\n",
      "Collecting Flask-Cors==3.0.3\n",
      "  Using cached Flask_Cors-3.0.3-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: future==0.16.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 16)) (0.16.0)\n",
      "Collecting gapic-google-cloud-datastore-v1==0.15.3\n",
      "  Using cached gapic_google_cloud_datastore_v1-0.15.3-py3-none-any.whl\n",
      "Collecting gapic-google-cloud-error-reporting-v1beta1==0.15.3\n",
      "  Using cached gapic_google_cloud_error_reporting_v1beta1-0.15.3-py3-none-any.whl\n",
      "Requirement already satisfied: gapic-google-cloud-logging-v2==0.91.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 19)) (0.91.3)\n",
      "Collecting gapic-google-cloud-pubsub-v1==0.15.4\n",
      "  Using cached gapic_google_cloud_pubsub_v1-0.15.4-py3-none-any.whl\n",
      "Collecting gapic-google-cloud-spanner-admin-database-v1==0.15.3\n",
      "  Using cached gapic_google_cloud_spanner_admin_database_v1-0.15.3-py3-none-any.whl\n",
      "Collecting gapic-google-cloud-spanner-admin-instance-v1==0.15.3\n",
      "  Using cached gapic_google_cloud_spanner_admin_instance_v1-0.15.3-py3-none-any.whl\n",
      "Collecting gapic-google-cloud-spanner-v1==0.15.3\n",
      "  Using cached gapic_google_cloud_spanner_v1-0.15.3-py3-none-any.whl\n",
      "Requirement already satisfied: google-auth==1.1.1 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 24)) (1.1.1)\n",
      "Collecting google-cloud==0.27.0\n",
      "  Using cached google_cloud-0.27.0-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting google-cloud-bigquery==0.26.0\n",
      "  Using cached google_cloud_bigquery-0.26.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting google-cloud-bigtable==0.26.0\n",
      "  Using cached google_cloud_bigtable-0.26.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: google-cloud-core==0.26.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 28)) (0.26.0)\n",
      "Collecting google-cloud-datastore==1.2.0\n",
      "  Using cached google_cloud_datastore-1.2.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting google-cloud-dns==0.26.0\n",
      "  Using cached google_cloud_dns-0.26.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting google-cloud-error-reporting==0.26.0\n",
      "  Using cached google_cloud_error_reporting-0.26.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting google-cloud-language==0.27.0\n",
      "  Using cached google_cloud_language-0.27.0-py2.py3-none-any.whl (71 kB)\n",
      "Collecting google-cloud-logging==1.2.0\n",
      "  Using cached google_cloud_logging-1.2.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting google-cloud-monitoring==0.26.0\n",
      "  Using cached google_cloud_monitoring-0.26.0-py2.py3-none-any.whl (34 kB)\n",
      "Collecting google-cloud-pubsub==0.27.0\n",
      "  Using cached google_cloud_pubsub-0.27.0-py2.py3-none-any.whl (33 kB)\n",
      "Collecting google-cloud-resource-manager==0.26.0\n",
      "  Using cached google_cloud_resource_manager-0.26.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting google-cloud-runtimeconfig==0.26.0\n",
      "  Using cached google_cloud_runtimeconfig-0.26.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting google-cloud-spanner==0.26.0\n",
      "  Using cached google_cloud_spanner-0.26.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting google-cloud-speech==0.28.0\n",
      "  Using cached google_cloud_speech-0.28.0-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-cloud-storage==1.3.2\n",
      "  Using cached google_cloud_storage-1.3.2-py2.py3-none-any.whl (46 kB)\n",
      "Collecting google-cloud-translate==1.1.0\n",
      "  Using cached google_cloud_translate-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-cloud-videointelligence==0.25.0\n",
      "  Using cached google_cloud_videointelligence-0.25.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting google-cloud-vision==0.26.0\n",
      "  Using cached google_cloud_vision-0.26.0-py2.py3-none-any.whl (68 kB)\n",
      "Collecting google-api-core==1.1.2\n",
      "  Using cached google_api_core-1.1.2-py2.py3-none-any.whl (50 kB)\n",
      "Collecting google-resumable-media==0.3.0\n",
      "  Using cached google_resumable_media-0.3.0-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: googleapis-common-protos==1.5.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 46)) (1.5.3)\n",
      "Requirement already satisfied: grpc-google-iam-v1==0.11.4 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 47)) (0.11.4)\n",
      "Requirement already satisfied: grpcio==1.6.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 48)) (1.6.3)\n",
      "Requirement already satisfied: html5lib==0.9999999 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 49)) (0.9999999)\n",
      "Requirement already satisfied: httplib2==0.10.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 50)) (0.10.3)\n",
      "Requirement already satisfied: idna==2.6 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 51)) (2.6)\n",
      "Collecting ipdb==0.10.3\n",
      "  Using cached ipdb-0.10.3-py3-none-any.whl\n",
      "Collecting ipython==6.2.1\n",
      "  Using cached ipython-6.2.1-py3-none-any.whl (745 kB)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 54)) (0.2.0)\n",
      "Collecting iso8601==0.1.12\n",
      "  Using cached iso8601-0.1.12-py3-none-any.whl (12 kB)\n",
      "Collecting itsdangerous==0.24\n",
      "  Using cached itsdangerous-0.24-py3-none-any.whl\n",
      "Collecting jamo==0.4.1\n",
      "  Using cached jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Collecting jedi==0.11.0\n",
      "  Using cached jedi-0.11.0-py2.py3-none-any.whl (146 kB)\n",
      "Collecting Jinja2==2.9.6\n",
      "  Using cached Jinja2-2.9.6-py2.py3-none-any.whl (340 kB)\n",
      "Collecting joblib==0.11\n",
      "  Using cached joblib-0.11-py2.py3-none-any.whl (176 kB)\n",
      "Collecting librosa==0.5.1\n",
      "  Using cached librosa-0.5.1-py3-none-any.whl\n",
      "Requirement already satisfied: llvmlite==0.20.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 62)) (0.20.0)\n",
      "Collecting m3u8==0.3.3\n",
      "  Using cached m3u8-0.3.3-py3-none-any.whl\n",
      "Collecting Markdown==2.6.9\n",
      "  Using cached Markdown-2.6.9-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe==1.1.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 65)) (1.1.0)\n",
      "Collecting matplotlib==2.1.0\n",
      "  Using cached matplotlib-2.1.0-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Requirement already satisfied: monotonic==1.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 67)) (1.3)\n",
      "Collecting nltk==3.2.5\n",
      "  Using cached nltk-3.2.5-py3-none-any.whl\n",
      "Collecting numba==0.35.0\n",
      "  Using cached numba-0.35.0-cp36-cp36m-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: numpy==1.13.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 70)) (1.13.3)\n",
      "Requirement already satisfied: oauth2client==3.0.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 71)) (3.0.0)\n",
      "Requirement already satisfied: parso==0.1.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 72)) (0.1.0)\n",
      "Collecting pexpect==4.2.1\n",
      "  Using cached pexpect-4.2.1-py2.py3-none-any.whl (55 kB)\n",
      "Collecting pickleshare==0.7.4\n",
      "  Using cached pickleshare-0.7.4-py2.py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: ply==3.8 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 75)) (3.8)\n",
      "Collecting prompt-toolkit==1.0.15\n",
      "  Using cached prompt_toolkit-1.0.15-py3-none-any.whl (247 kB)\n",
      "Requirement already satisfied: proto-google-cloud-datastore-v1==0.90.4 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 77)) (0.90.4)\n",
      "Requirement already satisfied: proto-google-cloud-error-reporting-v1beta1==0.15.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 78)) (0.15.3)\n",
      "Requirement already satisfied: proto-google-cloud-logging-v2==0.91.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 79)) (0.91.3)\n",
      "Requirement already satisfied: proto-google-cloud-pubsub-v1==0.15.4 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 80)) (0.15.4)\n",
      "Requirement already satisfied: proto-google-cloud-spanner-admin-database-v1==0.15.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 81)) (0.15.3)\n",
      "Requirement already satisfied: proto-google-cloud-spanner-admin-instance-v1==0.15.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 82)) (0.15.3)\n",
      "Requirement already satisfied: proto-google-cloud-spanner-v1==0.15.3 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 83)) (0.15.3)\n",
      "Requirement already satisfied: protobuf==3.4.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 84)) (3.4.0)\n",
      "Collecting ptyprocess==0.5.2\n",
      "  Using cached ptyprocess-0.5.2-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: pyasn1==0.3.7 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 86)) (0.3.7)\n",
      "Requirement already satisfied: pyasn1-modules==0.1.5 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 87)) (0.1.5)\n",
      "Collecting pydub==0.20.0\n",
      "  Using cached pydub-0.20.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting Pygments==2.2.0\n",
      "  Using cached Pygments-2.2.0-py2.py3-none-any.whl (841 kB)\n",
      "Collecting pyparsing==2.2.0\n",
      "  Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting python-dateutil==2.6.1\n",
      "  Using cached python_dateutil-2.6.1-py2.py3-none-any.whl (194 kB)\n",
      "Collecting pytz==2017.2\n",
      "  Using cached pytz-2017.2-py2.py3-none-any.whl (484 kB)\n",
      "Requirement already satisfied: requests==2.18.4 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 93)) (2.18.4)\n",
      "Collecting resampy==0.2.0\n",
      "  Using cached resampy-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: rsa==3.4.2 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 95)) (3.4.2)\n",
      "Collecting scikit-learn==0.19.0\n",
      "  Using cached scikit_learn-0.19.0-cp36-cp36m-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: simplegeneric==0.8.1 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 97)) (0.8.1)\n",
      "Requirement already satisfied: six==1.11.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 98)) (1.11.0)\n",
      "Requirement already satisfied: tenacity==4.4.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 99)) (4.4.0)\n",
      "Collecting tensorflow==1.3.0\n",
      "  Using cached tensorflow-1.3.0-cp36-cp36m-win_amd64.whl (25.5 MB)\n",
      "Collecting tensorflow-gpu==1.3.0\n",
      "  Using cached tensorflow_gpu-1.3.0-cp36-cp36m-win_amd64.whl (60.0 MB)\n",
      "Collecting tensorflow-tensorboard==0.1.8\n",
      "  Using cached tensorflow_tensorboard-0.1.8-py3-none-any.whl (1.6 MB)\n",
      "Collecting tinytag==0.18.0\n",
      "  Using cached tinytag-0.18.0-py3-none-any.whl\n",
      "Collecting tqdm==4.19.2\n",
      "  Using cached tqdm-4.19.2-py2.py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: traitlets==4.3.2 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 105)) (4.3.2)\n",
      "Requirement already satisfied: urllib3==1.22 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 106)) (1.22)\n",
      "Requirement already satisfied: wcwidth==0.1.7 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 107)) (0.1.7)\n",
      "Requirement already satisfied: Werkzeug==0.12.2 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from -r requirements.txt (line 108)) (0.12.2)\n",
      "Collecting youtube-dl==2017.10.15.1\n",
      "  Using cached youtube_dl-2017.10.15.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting unidecode==1.0.22\n",
      "  Using cached Unidecode-1.0.22-py2.py3-none-any.whl (235 kB)\n",
      "Collecting inflect==0.2.5\n",
      "  Using cached inflect-0.2.5-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: pyreadline>=1.7.1 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from dill==0.2.7.1->-r requirements.txt (line 12)) (2.1)\n",
      "Requirement already satisfied: google-gax<0.16dev,>=0.15.8 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from gapic-google-cloud-datastore-v1==0.15.3->-r requirements.txt (line 17)) (0.15.16)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from google-api-core==1.1.2->-r requirements.txt (line 44)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: colorama in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from ipython==6.2.1->-r requirements.txt (line 53)) (0.4.4)\n",
      "Collecting scipy>=0.13.0\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\jwj71\\anaconda3\\envs\\tf_test\\lib\\site-packages (from tensorflow==1.3.0->-r requirements.txt (line 100)) (0.37.0)\n",
      "  Using cached scipy-1.5.3-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "  Downloading scipy-1.5.2-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "  Using cached scipy-1.5.1-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "  Using cached scipy-1.5.0-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "  Using cached scipy-1.4.1-cp36-cp36m-win_amd64.whl (30.8 MB)\n",
      "Installing collected packages: scipy, Pygments, prompt-toolkit, pickleshare, numba, Markdown, Jinja2, jedi, itsdangerous, google-resumable-media, google-cloud-logging, gapic-google-cloud-spanner-v1, gapic-google-cloud-spanner-admin-instance-v1, gapic-google-cloud-spanner-admin-database-v1, gapic-google-cloud-pubsub-v1, gapic-google-cloud-error-reporting-v1beta1, gapic-google-cloud-datastore-v1, click, bleach, tensorflow-tensorboard, scikit-learn, resampy, pytz, python-dateutil, pyparsing, ptyprocess, joblib, iso8601, ipython, google-cloud-vision, google-cloud-videointelligence, google-cloud-translate, google-cloud-storage, google-cloud-speech, google-cloud-spanner, google-cloud-runtimeconfig, google-cloud-resource-manager, google-cloud-pubsub, google-cloud-monitoring, google-cloud-language, google-cloud-error-reporting, google-cloud-dns, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery, Flask, cycler, beautifulsoup4, audioread, youtube-dl, unidecode, tqdm, tinytag, tensorflow-gpu, tensorflow, pydub, pexpect, nltk, matplotlib, m3u8, librosa, jamo, ipdb, inflect, google-cloud, google-api-core, Flask-Cors, ffprobe, bs4, appnope\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.10.0\n",
      "    Uninstalling Pygments-2.10.0:\n",
      "      Successfully uninstalled Pygments-2.10.0\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.19\n",
      "    Uninstalling prompt-toolkit-3.0.19:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.19\n",
      "  Attempting uninstall: pickleshare\n",
      "    Found existing installation: pickleshare 0.7.5\n",
      "    Uninstalling pickleshare-0.7.5:\n",
      "      Successfully uninstalled pickleshare-0.7.5\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.0.1\n",
      "    Uninstalling Jinja2-3.0.1:\n",
      "      Successfully uninstalled Jinja2-3.0.1\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.18.0\n",
      "    Uninstalling jedi-0.18.0:\n",
      "      Successfully uninstalled jedi-0.18.0\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 4.0.0\n",
      "    Uninstalling bleach-4.0.0:\n",
      "      Successfully uninstalled bleach-4.0.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.16.1\n",
      "    Uninstalling ipython-7.16.1:\n",
      "      Successfully uninstalled ipython-7.16.1\n",
      "Successfully installed Flask-0.12.2 Flask-Cors-3.0.3 Jinja2-2.9.6 Markdown-2.6.9 Pygments-2.2.0 appnope-0.1.0 audioread-2.1.5 beautifulsoup4-4.6.0 bleach-1.5.0 bs4-0.0.1 click-6.7 cycler-0.10.0 ffprobe-0.5 gapic-google-cloud-datastore-v1-0.15.3 gapic-google-cloud-error-reporting-v1beta1-0.15.3 gapic-google-cloud-pubsub-v1-0.15.4 gapic-google-cloud-spanner-admin-database-v1-0.15.3 gapic-google-cloud-spanner-admin-instance-v1-0.15.3 gapic-google-cloud-spanner-v1-0.15.3 google-api-core-1.1.2 google-cloud-0.27.0 google-cloud-bigquery-0.26.0 google-cloud-bigtable-0.26.0 google-cloud-datastore-1.2.0 google-cloud-dns-0.26.0 google-cloud-error-reporting-0.26.0 google-cloud-language-0.27.0 google-cloud-logging-1.2.0 google-cloud-monitoring-0.26.0 google-cloud-pubsub-0.27.0 google-cloud-resource-manager-0.26.0 google-cloud-runtimeconfig-0.26.0 google-cloud-spanner-0.26.0 google-cloud-speech-0.28.0 google-cloud-storage-1.3.2 google-cloud-translate-1.1.0 google-cloud-videointelligence-0.25.0 google-cloud-vision-0.26.0 google-resumable-media-0.3.0 inflect-0.2.5 ipdb-0.10.3 ipython-6.2.1 iso8601-0.1.12 itsdangerous-0.24 jamo-0.4.1 jedi-0.11.0 joblib-0.11 librosa-0.5.1 m3u8-0.3.3 matplotlib-2.1.0 nltk-3.2.5 numba-0.35.0 pexpect-4.2.1 pickleshare-0.7.4 prompt-toolkit-1.0.15 ptyprocess-0.5.2 pydub-0.20.0 pyparsing-2.2.0 python-dateutil-2.6.1 pytz-2017.2 resampy-0.2.0 scikit-learn-0.19.0 scipy-1.4.1 tensorflow-1.3.0 tensorflow-gpu-1.3.0 tensorflow-tensorboard-0.1.8 tinytag-0.18.0 tqdm-4.19.2 unidecode-1.0.22 youtube-dl-2017.10.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbconvert 6.0.7 requires pygments>=2.4.1, but you have pygments 2.2.0 which is incompatible.\n",
      "jupyterlab-pygments 0.1.2 requires pygments<3,>=2.4.1, but you have pygments 2.2.0 which is incompatible.\n",
      "jupyterhub 1.4.2 requires jinja2>=2.11.0, but you have jinja2 2.9.6 which is incompatible.\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'nltk'\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt\n",
    "!python3 -c \"import nltk; nltk.download('punkt')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2408af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jwj71\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk;\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c2c8c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-9-c6d9348cd769>, line 149)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-c6d9348cd769>\"\u001b[1;36m, line \u001b[1;32m149\u001b[0m\n\u001b[1;33m    fn,encoding='UTF-8', news_ids, desc=\"Download news video+text\", parallel=True)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import m3u8\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "from functools import partial\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from utils import get_encoder_name, parallel_run, makedirs\n",
    "\n",
    "API_URL = 'http://api.jtbc.joins.com/ad/pre/NV10173083'\n",
    "BASE_URL = 'http://nsvc.jtbc.joins.com/API/News/Newapp/Default.aspx'\n",
    "\n",
    "def soupify(text):\n",
    "    return BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "def get_news_ids(page_id):\n",
    "    params = {\n",
    "        'NJC': 'NJC300',\n",
    "        'CAID': 'NC10011174',\n",
    "        'PGI': page_id,\n",
    "    }\n",
    "\n",
    "    response = requests.request(\n",
    "        method='GET', url=BASE_URL, params=params,\n",
    "    )\n",
    "    soup = soupify(response.text)\n",
    "\n",
    "    return [item.text for item in soup.find_all('news_id')]\n",
    "\n",
    "def download_news_video_and_content(\n",
    "        news_id, base_dir, chunk_size=32*1024,\n",
    "        video_dir=\"video\", asset_dir=\"assets\", audio_dir=\"audio\"):\n",
    "\n",
    "    video_dir = os.path.join(base_dir, video_dir)\n",
    "    asset_dir = os.path.join(base_dir, asset_dir)\n",
    "    audio_dir = os.path.join(base_dir, audio_dir)\n",
    "\n",
    "    makedirs(video_dir)\n",
    "    makedirs(asset_dir)\n",
    "    makedirs(audio_dir)\n",
    "\n",
    "    text_path = os.path.join(asset_dir, \"{}.txt\".format(news_id))\n",
    "    original_text_path = os.path.join(asset_dir, \"original-{}.txt\".format(news_id))\n",
    "\n",
    "    video_path = os.path.join(video_dir, \"{}.ts\".format(news_id))\n",
    "    audio_path = os.path.join(audio_dir, \"{}.wav\".format(news_id))\n",
    "\n",
    "    params = {\n",
    "        'NJC': 'NJC400',\n",
    "        'NID': news_id, # NB11515152\n",
    "        'CD': 'A0100',\n",
    "    }\n",
    "\n",
    "    response = requests.request(\n",
    "        method='GET', url=BASE_URL, params=params,\n",
    "    )\n",
    "    soup = soupify(response.text)\n",
    "\n",
    "    article_contents = soup.find_all('article_contents')\n",
    "\n",
    "    assert len(article_contents) == 1, \\\n",
    "            \"# of <article_contents> of {} should be 1: {}\".format(news_id, response.text)\n",
    "\n",
    "    text = soupify(article_contents[0].text).get_text() # remove <div>\n",
    "\n",
    "    with open(original_text_path, \"w\",encoding='UTF-8') as f:\n",
    "        f.write(text,encoding='UTF-8')\n",
    "\n",
    "    with open(text_path, \"w\",encoding='UTF-8') as f:\n",
    "        from nltk import sent_tokenize\n",
    "\n",
    "        text = re.sub(r'\\[.{0,80} :\\s.+]', '', text) # remove quote\n",
    "        text = re.sub(r'☞.+http.+\\)', '', text) # remove quote\n",
    "        text = re.sub(r'\\(https?:\\/\\/.*[\\r\\n]*\\)', '', text) # remove url\n",
    "\n",
    "        sentences = sent_tokenize(text)\n",
    "        sentences = [sent for sentence in sentences for sent in sentence.split('\\n') if sent]\n",
    "\n",
    "        new_texts = []\n",
    "        for sent in sentences:\n",
    "            sent = sent.strip()\n",
    "            sent = re.sub(r'\\([^)]*\\)', '', sent)\n",
    "            #sent = re.sub(r'\\<.{0,80}\\>', '', sent)\n",
    "            sent = sent.replace('…', '.')\n",
    "            new_texts.append(sent)\n",
    "\n",
    "        f.write(\"\\n\".join([sent for sent in new_texts if sent]),encoding='UTF-8')\n",
    "\n",
    "    vod_paths = soup.find_all('vod_path')\n",
    "\n",
    "    assert len(vod_paths) == 1, \\\n",
    "            \"# of <vod_path> of {} should be 1: {}\".format(news_id, response.text)\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        redirect_url = soup.find_all('vod_path')[0].text\n",
    "\n",
    "        list_url = m3u8.load(redirect_url).playlists[0].absolute_uri\n",
    "        video_urls = [segment.absolute_uri for segment in m3u8.load(list_url).segments]\n",
    "\n",
    "        with open(video_path, \"wb\") as f:\n",
    "            for url in video_urls:\n",
    "                response = requests.get(url, stream=True)\n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "                for chunk in response.iter_content(chunk_size):\n",
    "                    if chunk: # filter out keep-alive new chunks\n",
    "                        f.write(chunk,encoding='UTF-8')\n",
    "\n",
    "    if not os.path.exists(audio_path):\n",
    "        encoder = get_encoder_name()\n",
    "        command = \"{} -y -loglevel panic -i {} -ab 160k -ac 2 -ar 44100 -vn {}\".\\\n",
    "                format(encoder, video_path, audio_path)\n",
    "        subprocess.call(command, shell=True)\n",
    "\n",
    "    return True\n",
    "\n",
    "__file__ = \"C:\\\\Users\\\\jwj71\\\\Documents\\\\GitHub\\\\multi-speaker-tacotron-tensorflow\\\\datasets\\\\son\\\\download.py\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news_ids = []\n",
    "    page_idx = 1\n",
    "\n",
    "    base_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    news_id_path = os.path.join(base_dir, \"news_ids.json\")\n",
    "\n",
    "    if not os.path.exists(news_id_path):\n",
    "        while True:\n",
    "            tmp_ids = get_news_ids(page_idx)\n",
    "            if len(tmp_ids) == 0:\n",
    "                break\n",
    "\n",
    "            news_ids.extend(tmp_ids)\n",
    "            print(\" [*] Download page {}: {}/{}\".format(page_idx, len(tmp_ids), len(news_ids)))\n",
    "\n",
    "            page_idx += 1\n",
    "\n",
    "        with open(news_id_path, \"w\",encoding='UTF-8') as f:\n",
    "            json.dump(news_ids, f, indent=2, ensure_ascii=False)\n",
    "    else:\n",
    "        with open(news_id_path,encoding='UTF-8') as f:\n",
    "            news_ids = json.loads(f.read())\n",
    "\n",
    "    exceptions = [\"NB10830162\"]\n",
    "    news_ids = list(set(news_ids) - set(exceptions))\n",
    "\n",
    "    fn = partial(download_news_video_and_content, base_dir=base_dir)\n",
    "\n",
    "    results = parallel_run(\n",
    "            fn, news_ids, desc=\"Download news video+text\", parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce82c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
